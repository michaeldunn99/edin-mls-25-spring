{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Compare speed of KNN Functions ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use(\"module://matplotlib_inline.backend_inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import (\n",
    "    our_knn_L2_CUDA,\n",
    "    our_knn_L2_CUPY,\n",
    "    our_knn_cosine_CUPY,\n",
    "    our_knn_dot_CUPY,\n",
    "    our_knn_L1_CUPY,\n",
    "    our_knn_l2_triton,\n",
    "    our_knn_cosine_triton,\n",
    "    our_knn_dot_triton,\n",
    "    our_knn_l1_triton,\n",
    "    our_knn_l2_cpu,\n",
    "    our_knn_l1_cpu,\n",
    "    our_knn_cosine_cpu,\n",
    "    our_knn_dot_cpu,\n",
    "    test_knn_wrapper\n",
    "    \n",
    ")\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch, cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1967)\n",
    "N = 4_000_000\n",
    "D = 512\n",
    "A = np.random.rand(N,D).astype(np.float32)\n",
    "X = np.random.rand(D,)\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {\n",
    "    # \"L2\": [\n",
    "    #     our_knn_L2_CUDA,\n",
    "    #     our_knn_L2_CUPY,\n",
    "    #     our_knn_l2_triton,\n",
    "    #     our_knn_l2_cpu,\n",
    "    # ],\n",
    "    # \"L1\": [\n",
    "    #     our_knn_L1_CUPY,\n",
    "    #     our_knn_l1_triton,\n",
    "    #     our_knn_l1_cpu\n",
    "    # ],\n",
    "    # \"Cosine\": [\n",
    "    #     our_knn_cosine_CUPY,\n",
    "    #     our_knn_cosine_triton,\n",
    "    #     our_knn_cosine_cpu\n",
    "    # ],\n",
    "    \"Dot Product\": [\n",
    "        our_knn_dot_CUPY,\n",
    "        our_knn_dot_triton,\n",
    "        our_knn_dot_cpu,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running our_knn_dot_CUPY with 4000000 vectors of dimension 512 and K=10 for 10 times.\n",
      "our_knn_dot_CUPY - Result: [1534894 1390303 3413792 3622658  933929 2306566 1498634   51503 1215858\n",
      " 3298632], Number of Vectors: 4000000, Dimension: 512, K: 10, \n",
      "Time: 1764.895201 milliseconds.\n",
      "\n",
      "Running our_knn_dot_triton with 4000000 vectors of dimension 512 and K=10 for 10 times.\n",
      "our_knn_dot_triton - Result: [1534894 1390303 3413792 3622658  933929 2306566 1498634   51503 1215858\n",
      " 3298632], Number of Vectors: 4000000, Dimension: 512, K: 10, \n",
      "Time: 1791.846490 milliseconds.\n",
      "\n",
      "Running our_knn_dot_cpu with 4000000 vectors of dimension 512 and K=10 for 10 times.\n",
      "our_knn_dot_cpu - Result: [1534894 1390303 3413792 3622658  933929 2306566 1498634   51503 1215858\n",
      " 3298632], Number of Vectors: 4000000, Dimension: 512, K: 10, \n",
      "Time: 5745.416498 milliseconds.\n",
      "\n",
      "Dot Product\n",
      "our_knn_dot_CUPY: [1764.8952007293701]\n",
      "our_knn_dot_triton: [1791.846489906311]\n",
      "our_knn_dot_cpu: [5745.416498184204]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_list = {}\n",
    "for function_type, function_list in functions.items():\n",
    "    results_list[function_type]= []\n",
    "    for function in function_list:\n",
    "        inner_results_item = []\n",
    "        # âœ… Clear GPU memory\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "        cupy.get_default_memory_pool().free_all_blocks()\n",
    "        torch.cuda.synchronize()\n",
    "        #clear GPU memory\n",
    "        result = test_knn_wrapper(function, N, D, A, X, K, repeat=10)\n",
    "        inner_results_item.append(result[2])\n",
    "        results_item = {function.__name__: inner_results_item}\n",
    "        results_list[function_type].append(results_item)\n",
    "for function_type, function_list in results_list.items():\n",
    "    print(function_type)\n",
    "    for function in function_list:\n",
    "        for function_name, result in function.items():\n",
    "            print(f\"{function_name}: {result}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Print four graphs: Each graph should have 3 lines CUPY, Triton, CPU\n",
    "# #Graph should be in log-log scale but the x-axis should be power of 2\n",
    "# #Plotting the results\n",
    "# import matplotlib.pyplot as plt\n",
    "# def plot_results(results_list):\n",
    "#     for function_type, function_list in results_list.items():\n",
    "#         plt.figure()\n",
    "#         for function in function_list:\n",
    "#             for function_name, result in function.items():\n",
    "#                 plt.plot(vector_sizes, result, label=function_name)\n",
    "#         plt.xscale('log', base=2)\n",
    "#         plt.yscale('log')\n",
    "#         plt.xlabel('Vector Size')\n",
    "#         plt.ylabel('Time (s)')\n",
    "#         plt.title(function_type)\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "# plot_results(results_list)\n",
    "# #Plotting the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     44\u001b[39m         plt.figtext(\n\u001b[32m     45\u001b[39m             \u001b[32m0.5\u001b[39m, -\u001b[32m0.12\u001b[39m,\n\u001b[32m     46\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIn the case of the GPU accelerated libraries, these timings are inclusive of the memory transfer in the GPU. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m             fontsize=\u001b[32m10\u001b[39m\n\u001b[32m     53\u001b[39m         )\n\u001b[32m     54\u001b[39m         plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m(results_list)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m function \u001b[38;5;129;01min\u001b[39;00m function_list:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m function_name, result \u001b[38;5;129;01min\u001b[39;00m function.items():\n\u001b[32m     18\u001b[39m         plt.plot(\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m             \u001b[43mvector_sizes\u001b[49m,\n\u001b[32m     20\u001b[39m             result,\n\u001b[32m     21\u001b[39m             label=function_name.replace(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m).upper(),\n\u001b[32m     22\u001b[39m             color=colors[color_idx % \u001b[38;5;28mlen\u001b[39m(colors)],\n\u001b[32m     23\u001b[39m             linewidth=\u001b[32m2.5\u001b[39m,\n\u001b[32m     24\u001b[39m             marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     25\u001b[39m             markersize=\u001b[32m5\u001b[39m,\n\u001b[32m     26\u001b[39m         )\n\u001b[32m     27\u001b[39m         color_idx += \u001b[32m1\u001b[39m\n\u001b[32m     29\u001b[39m plt.xscale(\u001b[33m'\u001b[39m\u001b[33mlog\u001b[39m\u001b[33m'\u001b[39m, base=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'vector_sizes' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x750 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a modern seaborn style\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "# Optional: use a specific color palette\n",
    "colors = sns.color_palette(\"colorblind\")  # good for accessibility\n",
    "\n",
    "def plot_results(results_list):\n",
    "    for idx, (function_type, function_list) in enumerate(results_list.items()):\n",
    "        plt.figure(figsize=(8, 7.5))  # bigger, cleaner layout\n",
    "\n",
    "        color_idx = 0\n",
    "        for function in function_list:\n",
    "            for function_name, result in function.items():\n",
    "                plt.plot(\n",
    "                    vector_sizes,\n",
    "                    result,\n",
    "                    label=function_name.replace('_', ' ').upper(),\n",
    "                    color=colors[color_idx % len(colors)],\n",
    "                    linewidth=2.5,\n",
    "                    marker='o',\n",
    "                    markersize=5,\n",
    "                )\n",
    "                color_idx += 1\n",
    "\n",
    "        plt.xscale('log', base=2)\n",
    "        plt.yscale('log')\n",
    "\n",
    "        # Log ticks with base-2 labels\n",
    "        plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"$2^{{{int(np.log2(x))}}}$\"))\n",
    "\n",
    "        plt.xlabel(\"Vector Size (log scale)\", labelpad=10)\n",
    "        plt.ylabel(\"Time (s) (log scale, descending)\", labelpad=10)\n",
    "        plt.gca().invert_yaxis() \n",
    "        plt.title(f\"Average time to compute {function_type} distance between two random vectors\", fontsize=16, weight=\"bold\")\n",
    "\n",
    "        plt.legend(title=\"Implementation\", loc=\"best\", frameon=True)\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "                # Add caption below the plot\n",
    "        plt.figtext(\n",
    "            0.5, -0.12,\n",
    "            \"In the case of the GPU accelerated libraries, these timings are inclusive of the memory transfer in the GPU. \"\n",
    "            \"As we can see here, CPU performance is better at lower dimensions and scales similarly with CuPy and Triton as the memory increases.\\n\\n\"\n",
    "            \"We note here that this is because there is only one distance calculation being carried out and, despite parallelising across segments within the vectors \"\n",
    "            \"and reducing these partial sums, the memory overhead involved means that there is no significant benefit from utilizing the GPU for a single distance calculation.\",\n",
    "            wrap=True,\n",
    "            ha=\"center\",\n",
    "            fontsize=10\n",
    "        )\n",
    "        plt.show()\n",
    "plot_results(results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
